{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 47, "column": 0}, "map": {"version":3,"sources":["file:///home/kaif9999/genvr/TexttoVideo/src/app/api/whisper/route.ts"],"sourcesContent":["import { NextResponse } from \"next/server\";\nimport Replicate from \"replicate\";\n\n// Initialize Replicate API client\nconst replicate = new Replicate({\n  auth: process.env.REPLICATE_API_KEY || \"\", // Add your Replicate API key here\n});\n\nexport async function POST(req: Request) {\n  try {\n    const formData = await req.formData(); // Get the form data from the request\n    const audioFile = formData.get(\"audio\") as File; // Extract the audio file\n\n    if (!audioFile) {\n      return NextResponse.json(\n        { error: \"Audio file is required!\" },\n        { status: 400 }\n      );\n    }\n\n    // Call the Replicate API to transcribe audio\n    const transcriptionModel = \"openai/whisper:8099696689d249cf8b122d833c36ac3f75505c666a395ca40ef26f68e7d3d16e\"; // Replace with actual model ID for Whisper\n    const transcriptionResponse = await replicate.run(transcriptionModel, {\n      input: {\n        audio: audioFile, // Pass the audio file to the model\n      },\n    });\n\n    // Ensure the transcription response is structured correctly\n    if (!transcriptionResponse || typeof transcriptionResponse !== 'object') {\n      return NextResponse.json(\n        { error: \"Failed to transcribe audio.\" },\n        { status: 500 }\n      );\n    }\n    // console.log(transcriptionResponse)\n    // Extract the transcription text from the response\n    const transcriptionText = (transcriptionResponse as any).transcription; // Use 'any' to bypass type checking for this property\n\n    if (!transcriptionText || typeof transcriptionText !== 'string') {\n      return NextResponse.json(\n        { error: \"Transcription not found in the response.\" },\n        { status: 500 }\n      );\n    }\n\n    // Return the transcription result\n    return NextResponse.json({\n      transcription: transcriptionText, // The transcribed text\n    });\n  } catch (error) {\n    console.error(\"Error while transcribing audio:\", error);\n    return NextResponse.json(\n      { error: \"An error occurred while processing your request.\" },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;AAAA;AACA;;;AAEA,kCAAkC;AAClC,MAAM,YAAY,IAAI,oIAAA,CAAA,UAAS,CAAC;IAC9B,MAAM,QAAQ,GAAG,CAAC,iBAAiB,IAAI;AACzC;AAEO,eAAe,KAAK,GAAY;IACrC,IAAI;QACF,MAAM,WAAW,MAAM,IAAI,QAAQ,IAAI,qCAAqC;QAC5E,MAAM,YAAY,SAAS,GAAG,CAAC,UAAkB,yBAAyB;QAE1E,IAAI,CAAC,WAAW;YACd,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA0B,GACnC;gBAAE,QAAQ;YAAI;QAElB;QAEA,6CAA6C;QAC7C,MAAM,qBAAqB,mFAAmF,2CAA2C;QACzJ,MAAM,wBAAwB,MAAM,UAAU,GAAG,CAAC,oBAAoB;YACpE,OAAO;gBACL,OAAO;YACT;QACF;QAEA,4DAA4D;QAC5D,IAAI,CAAC,yBAAyB,OAAO,0BAA0B,UAAU;YACvE,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA8B,GACvC;gBAAE,QAAQ;YAAI;QAElB;QACA,qCAAqC;QACrC,mDAAmD;QACnD,MAAM,oBAAoB,AAAC,sBAA8B,aAAa,EAAE,sDAAsD;QAE9H,IAAI,CAAC,qBAAqB,OAAO,sBAAsB,UAAU;YAC/D,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA2C,GACpD;gBAAE,QAAQ;YAAI;QAElB;QAEA,kCAAkC;QAClC,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;YACvB,eAAe;QACjB;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,mCAAmC;QACjD,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAmD,GAC5D;YAAE,QAAQ;QAAI;IAElB;AACF"}},
    {"offset": {"line": 107, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}